{"content": "Why is the matrix-defined Cross Product of two 3D vectors always orthogonal?\n\nBy matrix-defined, I mean [imath]\\left<a,b,c\\right>\\times\\left<d,e,f\\right> = \\left|     \\begin{array}{ccc}  i & j & k\\\\  a & b & c\\\\  d & e & f  \\end{array}    \\right|[/imath] ...instead of the definition of the product of the magnitudes multiplied by the sign of their angle, in the direction orthogonal) If I try cross producting two vectors with no [imath]k[/imath] component, I get one with only [imath]k[/imath], which is expected. But why? As has been pointed out, I am asking why the algebraic definition lines up with the geometric definition. \n\n__ANSWER__\n\nAssuming you know the definition of orthogonal as \"a is orthogonal to b iff [imath]a\\cdot b=0[/imath] then we could calculate [imath](a \\times b)\\cdot a = a_1(a_2b_3-a_3b_2)-a_2(a_1b_3-a_3b_1)-a_3(a_1b_2-a_2b_1)=0[/imath] and  [imath](a \\times b)\\cdot b-0[/imath], so the cross product is orthogonal to both. As Nold mentioned, if the two vectors a and b lie in the x,y plane, then the orthogonal vectors must be purely in the z direction. ", "extern_id": "53", "tags": "<linear_algebra><matrices><inner_product_space><orthogonality><cross_product>", "title": "upvote: 4", "url": "53"}