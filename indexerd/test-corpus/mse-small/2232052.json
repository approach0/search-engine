{"text": "Why my algorithm proximal gradient descent algorithm does not converge when I use momentum?\n\nI'm trying to solve following convex optimization function:\n[imath]min_W g(W) + h(W)[/imath], where the [imath]g[/imath] is convex and differentiable and [imath]h[/imath] in convex an non-smooth.\n[imath]g(W)=||Y-WX||_F^2[/imath] is square loss function.\nNote that,[imath]X,W,Y[/imath] all are matrices.\n[imath]h(W)[/imath] is non-smooth function with known proximal operator (shoft-tresholding(shirnkage(W))).\nI use fixed step size (t_k=0.02). I tried to do backtracking line search, but I was not sure how to extend it to the case where [imath]Y and W[/imath] are matrices (when they are both vectors, it's pretty easy to do it)\nUnfortunately when I use momentum (Nestrove acceleration approach), my algorithm does not converge.\nHere how I compute momentum:\n[imath]W^{(0)}=W^{(-1)} \\in R^n[/imath], we repeat:\n[imath]v=W^{(W-1)} + \\frac{k-2}{k-1}(W^{(k-1)}-W^{(k-1)})[/imath]\n[imath]W^{(k)}=prox_{tk}(v-t_k\\nabla g(v))[/imath]\nfor k=1,2,3,....\nDoes anybody have some hints regarding computing momentum for accelerared proximal gradient descent method ?\nsecond, is it possible to adapt back-tracking line search for the case where [imath]Y and  W[/imath] are matrices ? \n\nYou're probably referring to a work by Nesterov. Please provide all info: which paper are you referring to precisely ? What is [imath]t_k[/imath] provide the exact expression you're using) ?, etc.\nI would like to add momentum to the proximal gradient descent and run it with fixed step-size.  t_k is step size.\nWhat is the value of [imath]t_k[/imath] you're using ? How's it computed ? As your question stands it ap,pears you're trying ad hac amendments to an unknown algorithm. Talking about momentum, what paper are you referring to ? The more details you provide, the more help you'll get here. Nobody will invest more effort answering your question than the effort you invest writing it down properly in the first place...\nIf [imath]t_k = 0.02  > 1 / L_{\\nabla g} = 1 / \\|X\\|_2^2[/imath], then your algorithm might diverge...\nI gave it to so in my previous comment: [imath]L_{\\nabla g} = \\|X\\|_2^2 = \\sigma_{\\text{max}}^2(X)[/imath].\n\n", "url": "http://math.stackexchange.com/questions/2232052/why-my-algorithm-proximal-gradient-descent-algorithm-does-not-converge-when-i-us"}